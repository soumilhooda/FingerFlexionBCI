{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "sub1_train_data = loadmat('train_data_sub1.mat')\n",
    "sub1_train_label = loadmat('train_label_sub1.mat')\n",
    "sub1_test_data = loadmat('test_data_sub1.mat')\n",
    "\n",
    "# sub2_train_data = loadmat('train_data_sub2.mat')\n",
    "# sub2_train_label = loadmat('train_label_sub2.mat')\n",
    "\n",
    "# sub3_train_data = loadmat('train_data_sub3.mat')\n",
    "# sub3_train_label = loadmat('train_label_sub3.mat')\n",
    "\n",
    "sub1_train_data_arr = sub1_train_data[\"train_data\"]\n",
    "sub1_train_label_arr = sub1_train_label[\"train_dg\"]\n",
    "sub1_test_data_arr = sub1_test_data[\"test_data\"]\n",
    "\n",
    "# sub2_train_data_arr = sub2_train_data[\"train_data\"]\n",
    "# sub2_train_label_arr = sub2_train_label[\"train_dg\"]\n",
    "\n",
    "# sub3_train_data_arr = sub3_train_data[\"train_data\"]\n",
    "# sub3_train_label_arr = sub3_train_label[\"train_dg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1_train_data_arr = np.delete(sub1_train_data_arr, 54, 1)\n",
    "sub1_test_data_arr = np.delete(sub1_test_data_arr, 54, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(sub1_train_data_arr)\n",
    "X_train_scaled = scaler.transform(sub1_train_data_arr)\n",
    "X_test_scaled = scaler.transform(sub1_test_data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 01:08:11.220419: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-20 01:08:11.220953: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               31744     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 196,613\n",
      "Trainable params: 196,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 360000 samples, validate on 40000 samples\n",
      "Epoch 1/20\n",
      "360000/360000 [==============================] - 191s 530us/step - loss: 0.9089 - mae: 0.5553 - val_loss: 1.0116 - val_mae: 0.5944\n",
      "Epoch 2/20\n",
      "360000/360000 [==============================] - 183s 509us/step - loss: 0.6652 - mae: 0.4933 - val_loss: 1.1786 - val_mae: 0.6776\n",
      "Epoch 3/20\n",
      "360000/360000 [==============================] - 169s 469us/step - loss: 0.3854 - mae: 0.3945 - val_loss: 1.2010 - val_mae: 0.6725\n",
      "Epoch 4/20\n",
      "360000/360000 [==============================] - 163s 453us/step - loss: 0.2158 - mae: 0.3059 - val_loss: 1.1771 - val_mae: 0.6635\n",
      "Epoch 5/20\n",
      "360000/360000 [==============================] - 153s 424us/step - loss: 0.1383 - mae: 0.2537 - val_loss: 1.1960 - val_mae: 0.6586\n",
      "Epoch 6/20\n",
      "360000/360000 [==============================] - 149s 414us/step - loss: 0.1025 - mae: 0.2229 - val_loss: 1.1882 - val_mae: 0.6602\n",
      "Epoch 7/20\n",
      "360000/360000 [==============================] - 154s 428us/step - loss: 0.0824 - mae: 0.2020 - val_loss: 1.1920 - val_mae: 0.6621\n",
      "Epoch 8/20\n",
      "360000/360000 [==============================] - 148s 412us/step - loss: 0.0696 - mae: 0.1867 - val_loss: 1.1941 - val_mae: 0.6531\n",
      "Epoch 9/20\n",
      "360000/360000 [==============================] - 164s 456us/step - loss: 0.0605 - mae: 0.1747 - val_loss: 1.2060 - val_mae: 0.6689\n",
      "Epoch 10/20\n",
      "360000/360000 [==============================] - 153s 425us/step - loss: 0.0538 - mae: 0.1651 - val_loss: 1.1866 - val_mae: 0.6556\n",
      "Epoch 11/20\n",
      "360000/360000 [==============================] - 141s 391us/step - loss: 0.0485 - mae: 0.1572 - val_loss: 1.2088 - val_mae: 0.6571\n",
      "Epoch 12/20\n",
      "360000/360000 [==============================] - 148s 410us/step - loss: 0.0445 - mae: 0.1507 - val_loss: 1.1940 - val_mae: 0.6580\n",
      "Epoch 13/20\n",
      "360000/360000 [==============================] - 139s 386us/step - loss: 0.0413 - mae: 0.1453 - val_loss: 1.1979 - val_mae: 0.6588\n",
      "Epoch 14/20\n",
      "360000/360000 [==============================] - 128s 356us/step - loss: 0.0386 - mae: 0.1406 - val_loss: 1.1807 - val_mae: 0.6531\n",
      "Epoch 15/20\n",
      "360000/360000 [==============================] - 125s 348us/step - loss: 0.0362 - mae: 0.1363 - val_loss: 1.1846 - val_mae: 0.6566\n",
      "Epoch 16/20\n",
      "360000/360000 [==============================] - 112s 310us/step - loss: 0.0343 - mae: 0.1327 - val_loss: 1.1827 - val_mae: 0.6504\n",
      "Epoch 17/20\n",
      "360000/360000 [==============================] - 82s 228us/step - loss: 0.0326 - mae: 0.1294 - val_loss: 1.2145 - val_mae: 0.6744\n",
      "Epoch 18/20\n",
      "360000/360000 [==============================] - 79s 218us/step - loss: 0.0311 - mae: 0.1265 - val_loss: 1.1700 - val_mae: 0.6399\n",
      "Epoch 19/20\n",
      "360000/360000 [==============================] - 78s 216us/step - loss: 0.0299 - mae: 0.1240 - val_loss: 1.1856 - val_mae: 0.6521\n",
      "Epoch 20/20\n",
      "360000/360000 [==============================] - 79s 220us/step - loss: 0.0286 - mae: 0.1215 - val_loss: 1.1916 - val_mae: 0.6588\n",
      "[0.9089303214655983, 0.6652418710973528, 0.3853657939420806, 0.21576613278720114, 0.1383150356852346, 0.10246408997807238, 0.08243595855169826, 0.06959841322998206, 0.06048814750048849, 0.05383994022260109, 0.04851180916710032, 0.04452939253350099, 0.04127329844699965, 0.03859729710817337, 0.0362018835188614, 0.034290690680676035, 0.03255915720744265, 0.031073988270676797, 0.029862971577131085, 0.028600849274711477]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=61, activation='sigmoid'))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "#Output layer\n",
    "model.add(Dense(5, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train_scaled, sub1_train_label_arr, validation_split=0.1, epochs=20)\n",
    "\n",
    "loss = history.history['loss']\n",
    "print(loss)\n",
    "np.savetxt('loss_testSub1_drop54.ascii',(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values are:  [[-0.39140022 -0.29349697 -0.5068352  -0.47745273 -0.39100242]\n",
      " [-0.3608983  -0.2849123  -0.5284451  -0.4546164  -0.38549864]\n",
      " [-0.34838238 -0.2505514  -0.52181506 -0.38493112 -0.3972881 ]\n",
      " ...\n",
      " [-0.16143188 -0.69238067 -0.48360184 -0.5773777  -0.60718054]\n",
      " [-0.14816166 -0.7387056  -0.5120534  -0.5819162  -0.6591191 ]\n",
      " [-0.14595036 -0.7719569  -0.5233601  -0.5919265  -0.691022  ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "print(\"Predicted values are: \", predictions)\n",
    "# print(\"Real values are: \", y_test)\n",
    "# np.savetxt ('output1_test.ascii',(y_test))\n",
    "np.savetxt ('outputSub1_drop54_test.ascii',(predictions))\n",
    "# mse_neural, mae_neural = model.evaluate(X_test_scaled, y_test)\n",
    "# print('Mean squared error from neural net: ', mse_neural)\n",
    "# print('Mean absolute error from neural net: ', mae_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"modelSub1_drop54_test.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "    model.save_weights(\"modelSub1_drop54_test.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('ML_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e075f35889cf4896b84e6091500e0536ffb720a60a1416c24df33b82d7beac2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
