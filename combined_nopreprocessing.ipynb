{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio \n",
    "import scipy.signal as sig\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import random \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Reshape, Conv1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = [sio.loadmat(f'Data/BCICIV_4_mat/sub{x}_comp.mat',struct_as_record=True) for x in range(1,4)]\n",
    "tdat = [sio.loadmat(f'Data/sub{x}_testlabels.mat',struct_as_record=True) for x in range(1,4)]\n",
    "\n",
    "train_data = [dat[x]['train_data'] for x in range(3)]\n",
    "test_data = ([dat[x]['test_data'] for x in range(3) ])\n",
    "train_dg = ([dat[x]['train_dg'] for x in range(3) ])\n",
    "test_dg = ([tdat[x]['test_dg'] for x in range(3) ])\n",
    "\n",
    "train_samples = [train_data[i].shape[0] for i in range(3)]\n",
    "channels = [train_data[i].shape[1] for i in range(3)]\n",
    "test_samples = [test_data[i].shape[0] for i in range(3)]\n",
    "channel_train_data = [np.transpose(train_data[i],(1,0)) for i in range(3)]\n",
    "channel_test_data = [np.transpose(test_data[i],(1,0)) for i in range(3)]\n",
    "finger_train_data = [np.transpose(train_dg[i],(1,0)) for i in range(3)]\n",
    "finger_test_data = [np.transpose(test_dg[i],(1,0)) for i in range(3)]\n",
    "\n",
    "sampling_frequency = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "merch_train = []\n",
    "merch_test = []\n",
    "for i in range(max(channels)):\n",
    "    merch = []\n",
    "    for c in range(len(channel_train_data)):\n",
    "        if(i >= channels[c]):\n",
    "            for j in range(train_samples[c]):\n",
    "                merch.append(0)\n",
    "        else:\n",
    "            for val in channel_train_data[c][i]:\n",
    "                merch.append(val)\n",
    "    merch_train.append(merch)\n",
    "\n",
    "for i in range(max(channels)):\n",
    "    merch = []\n",
    "    for c in range(len(channel_test_data)):\n",
    "        if(i >= channels[c]):\n",
    "            for j in range(test_samples[c]):\n",
    "                merch.append(0)\n",
    "        else:\n",
    "            for val in channel_test_data[c][i]:\n",
    "                merch.append(val)\n",
    "    merch_test.append(merch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "merf_train = []\n",
    "for i in range(5):\n",
    "    merf = []\n",
    "    for f in finger_train_data:\n",
    "        for val in f[i]:\n",
    "            merf.append(val)\n",
    "    merf_train.append(merf)\n",
    "\n",
    "merf_test = []\n",
    "for i in range(5):\n",
    "    merf = []\n",
    "    for f in finger_test_data:\n",
    "        for val in f[i]:\n",
    "            merf.append(val)\n",
    "    merf_test.append(merf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "1200000\n",
      "64\n",
      "5\n",
      "1200000\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(merch_train))\n",
    "print(len(merch_train[0]))\n",
    "print(len(merch_test))\n",
    "print(len(merf_train))\n",
    "print(len(merf_train[0]))\n",
    "print(len(merf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_states(finger_data):\n",
    "#     # State assignment : (0 : rest, 1-5 finger flexed)\n",
    "#     dsamples = len(finger_data[0])\n",
    "#     states = [None]*dsamples\n",
    "#     threshold_1,threshold_2  = 2.0,1.0\n",
    "#     for i in range(dsamples):\n",
    "#         flex,rest = 0,0\n",
    "#         for j in range(5):\n",
    "#             if finger_data[j][i] >= threshold_1:\n",
    "#                 states[i] = j + 1\n",
    "#                 flex += 1\n",
    "#             elif finger_data[j][i] < threshold_2:\n",
    "#                 rest += 1\n",
    "#         if states[i] == None:\n",
    "#             if rest:\n",
    "#                 states[i] = 0\n",
    "\n",
    "#     return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merf_train_states = assign_states(merf_train)\n",
    "# merf_test_states = assign_states(merf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200000\n"
     ]
    }
   ],
   "source": [
    "# print(len(merf_train_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trc = np.array(merch_train)\n",
    "trf = np.array(merf_train)\n",
    "\n",
    "tec = np.array(merch_test)\n",
    "tef = np.array(merf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finger One-Hot Encoding\n",
    "\n",
    "# trf = trf.reshape(len(trf), 1)\n",
    "# trf = OneHotEncoder(sparse=False).fit_transform(trf)\n",
    "\n",
    "# tef = tef.reshape(len(tef), 1)\n",
    "# tef = OneHotEncoder(sparse=False).fit_transform(tef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 64)\n",
      "(600000, 64)\n"
     ]
    }
   ],
   "source": [
    "trc = trc.T\n",
    "tec = tec.T\n",
    "print(trc.shape)\n",
    "print(tec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = trf.T\n",
    "tef = tef.T\n",
    "trf = trf.reshape(len(trf),5)\n",
    "tef = tef.reshape(len(tef),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECoG + Finger Normalization\n",
    "\n",
    "trc = Normalizer().fit(trc).transform(trc)\n",
    "tec = Normalizer().fit(tec).transform(tec)\n",
    "trf = Normalizer().fit(trf).transform(trf)\n",
    "tef = Normalizer().fit(tef).transform(tef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to 3D Structure for Conv and BiLSTM\n",
    "\n",
    "trc = trc.reshape(len(trc),1,len(trc[0]))\n",
    "tec = tec.reshape(len(tec),1,len(tec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trc_finger_nonhotencoded = np.argmax(trf,axis=1)\n",
    "# tec_finger_nonhotencoded = np.argmax(tef,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 1, 64)             4160      \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1, 48)             3120      \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 24)                5856      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 125       \n",
      "=================================================================\n",
      "Total params: 13,261\n",
      "Trainable params: 13,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1140000 samples, validate on 60000 samples\n",
      "Epoch 1/5\n",
      "1140000/1140000 [==============================] - 38s 33us/sample - loss: -90146.7524 - mae: 0.5158 - mse: 0.4589 - val_loss: 373185.7218 - val_mae: 0.4993 - val_mse: 0.4571\n",
      "Epoch 2/5\n",
      "1140000/1140000 [==============================] - 21s 18us/sample - loss: -3430556.6328 - mae: 0.5164 - mse: 0.4633 - val_loss: 14976533.0583 - val_mae: 0.4679 - val_mse: 0.3639\n",
      "Epoch 3/5\n",
      "1140000/1140000 [==============================] - 26s 23us/sample - loss: -86928557.3491 - mae: 0.5150 - mse: 0.4576 - val_loss: 170216377.7708 - val_mae: 0.4679 - val_mse: 0.3639\n",
      "Epoch 4/5\n",
      "1140000/1140000 [==============================] - 27s 24us/sample - loss: -427088694.3719 - mae: 0.5147 - mse: 0.4562 - val_loss: 616807139.4000 - val_mae: 0.4993 - val_mse: 0.4571\n",
      "Epoch 5/5\n",
      "1140000/1140000 [==============================] - 27s 24us/sample - loss: -1203729677.2491 - mae: 0.5146 - mse: 0.4559 - val_loss: 1508882526.0000 - val_mae: 0.4679 - val_mse: 0.3639\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Conv1D(64, 1, activation='relu', input_shape=(1,64)))\n",
    "model.add(Conv1D(48, 1, activation='relu', ))\n",
    "forward_layer = LSTM(12, activation='relu')\n",
    "backward_layer = LSTM(12, activation='relu', go_backwards=True)\n",
    "model.add(Bidirectional(forward_layer, backward_layer=backward_layer))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['mae','mse'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(trc, trf, batch_size = 2000, epochs=5, validation_split=0.05)\n",
    "\n",
    "predictions_tr = model.predict(trc)\n",
    "predictions_te = model.predict(tec)\n",
    "# predictions_tr = np.argmax(predictions_tr, axis = 1)\n",
    "# predictions_te = np.argmax(predictions_te, axis = 1)\n",
    "np.savetxt('predictions_tr_combined.txt',predictions_tr)\n",
    "np.savetxt('predictions_te_combined.txt',predictions_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q1/d82dt4ns3kd7h9yk5cv3ysfr0000gn/T/ipykernel_3695/2283708946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "corr = np.corrcoef(tef, predictions_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('ML_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e075f35889cf4896b84e6091500e0536ffb720a60a1416c24df33b82d7beac2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
